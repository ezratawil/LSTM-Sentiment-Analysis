{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1D02Fvoqhk8uC9U2vGH0FUF6RZDmZMODM",
      "authorship_tag": "ABX9TyNQ+zJatSnztXUQXHnE/mI8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports\n"
      ],
      "metadata": {
        "id": "BbmZS4xBbAOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3hYk46Gla1Xy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26030429-1aaf-4720-ef87-4a68fb516bfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "import string\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "from keras.layers import Embedding, Dense, Dropout, Input, LSTM, GlobalMaxPooling1D\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import curated data for processing"
      ],
      "metadata": {
        "id": "49TUTo5rggCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "amazon = pd.read_csv('/content/drive/MyDrive/NLP/amazon.csv')\n",
        "imdb = pd.read_csv('/content/drive/MyDrive/NLP/imdb_proc.csv')\n",
        "yelp = pd.read_csv('/content/drive/MyDrive/NLP/yelp.csv')"
      ],
      "metadata": {
        "id": "-5YrEwdXlSv4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(amazon.value_counts(amazon['label']))\n",
        "print(imdb.value_counts(imdb['label']))\n",
        "print(yelp.value_counts(yelp['label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSYe8hX_SHKm",
        "outputId": "8142394c-7807-4235-c4f8-57e6e107bfed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    2000000\n",
            "0    2000000\n",
            "dtype: int64\n",
            "label\n",
            "1    25000\n",
            "0    25000\n",
            "dtype: int64\n",
            "label\n",
            "1    299000\n",
            "0    299000\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split into train and test at this point, \n",
        "# because datasets vary in size, so we would like a porportional sample of each \n",
        "# dataset for training, and we would also like to stratify our sampling so we\n",
        "# get a porportional amount of negative and positive sentiment texts to \n",
        "# train/fit the model to\n",
        "\n",
        "# amazon data too large for model training time , reduce to 1M samples\n",
        "amazon_keep , amazon_drop =  train_test_split(amazon, test_size=0.8, random_state=0, stratify=amazon[['label']])\n",
        "\n",
        "amazon_train,amazon_test = train_test_split(amazon_keep,test_size=0.2,random_state=0,stratify=amazon_keep[['label']])\n",
        "amazon_train, amazon_val =  train_test_split(amazon_train, test_size=0.2, random_state=0, stratify=amazon_train[['label']])\n",
        "\n",
        "yelp_train, yelp_test =  train_test_split(yelp, test_size=0.15, random_state=0, stratify=yelp[['label']])\n",
        "yelp_train, yelp_val =  train_test_split(yelp_train, test_size=0.2, random_state=0, stratify=yelp_train[['label']])\n",
        "\n",
        "imdb_train, imdb_test = train_test_split(imdb, test_size=0.15, random_state=0, stratify=imdb[['label']])\n",
        "imdb_train, imdb_val = train_test_split(imdb_train, test_size=0.2, random_state=0, stratify=imdb_train[['label']])"
      ],
      "metadata": {
        "id": "dKxF4WEdnZRR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total 952640 training instances\n",
        "train_data = pd.concat([amazon_train,yelp_train,imdb_train],ignore_index=True)\n",
        "# total 257200 validation instances\n",
        "val_data = pd.concat([amazon_val,yelp_val,imdb_val],ignore_index=True)\n",
        "# total 238160 testing instances\n",
        "test_data = pd.concat([amazon_test,yelp_test,imdb_test],ignore_index=True)\n",
        "# remove unnecessary cols\n",
        "train_data.drop(['Unnamed: 0','website'],axis=1,inplace=True)\n",
        "test_data.drop(['Unnamed: 0','website'],axis=1,inplace=True)\n",
        "val_data.drop(['Unnamed: 0','website'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "8N70RTuM2M1C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train: {train_data.shape}, test: {test_data.shape}, val: {val_data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwPM6xt2tBBz",
        "outputId": "e9a199be-07f3-408a-a4b9-fb752c0f3edd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: (952640, 2), test: (257200, 2), val: (238160, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "nFSH5aDMfF7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "counter = Counter()\n",
        "FREQ = set([word for (word,word_count) in counter.most_common(15)])\n",
        "rare_words = 200000\n",
        "RARE = set([word for (word, word_count) in counter.most_common()[:-rare_words-1:-1]])\n",
        "# func to remove all punctuation\n",
        "def remove_punc(text):\n",
        "  return text.translate(str.maketrans('', '', string.punctuation))\n",
        "# func to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "  return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "# func to remove 15 most frequent words ()\n",
        "def remove_freq(text):\n",
        "  return \" \".join([word for word in str(text).split() if word not in FREQ])\n",
        "\n",
        "def remove_rare(text):\n",
        "  return \" \".join([word for word in str(text).split() if word not in RARE])\n",
        "\n",
        "\n",
        "\n",
        "def preprocess(df,dis=False):\n",
        "  df[\"text\"] = df[\"text\"].apply(lambda text: remove_punc(text))\n",
        "  df[\"text\"] = df[\"text\"].apply(lambda text: remove_stopwords(text))\n",
        "  df[\"text\"] = df[\"text\"].apply(lambda text: remove_freq(text))\n",
        "  df[\"text\"] = df[\"text\"].apply(lambda text: remove_rare(text))\n",
        "  \n",
        "preprocessing = FunctionTransformer(preprocess) # make transformer for pipeline use\n",
        "\n"
      ],
      "metadata": {
        "id": "QrGGBb_O2rFS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prep_pipe = Pipeline([('preprocessing',preprocessing)])\n",
        "\n",
        "prep_pipe.fit_transform(train_data)\n",
        "\n",
        "prep_pipe.transform(val_data)\n",
        "\n",
        "prep_pipe.transform(test_data)"
      ],
      "metadata": {
        "id": "RVuBm3oU4UKZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize and pad sequences"
      ],
      "metadata": {
        "id": "vRodqE0jgSJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/NLP/train_proc.csv')\n",
        "val_data = pd.read_csv('/content/drive/MyDrive/NLP/val_proc.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/NLP/test_proc.csv')\n",
        "\n",
        "train_data = train_data.sample(frac=1).reset_index(drop=True) # shuffle datasets\n",
        "val_data = val_data.sample(frac=1).reset_index(drop=True)\n",
        "test_data = test_data.sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pTbFQ3zdBXck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "train_data.dropna(inplace=True)\n",
        "val_data.dropna(inplace=True)\n",
        "X_train,y_train = train_data['text'],train_data['label']\n",
        "X_val,y_val = val_data['text'],val_data['label']\n",
        "X_test,y_test = test_data['text'],test_data['label']"
      ],
      "metadata": {
        "id": "K7-AmhrnhCMq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only 100000 most common words, oov = out of vocabulary token, \n",
        "# used to replace words not in vocab \n",
        "tokenizer = Tokenizer(num_words=100000, oov_token='<UNK>') \n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "vocab_size\n"
      ],
      "metadata": {
        "id": "wYvnJ1TFhQO_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a60ec3-5171-4029-906d-01c4f21df892"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1098481"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def get_sequences(tokenizer, text):\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=100, padding='post')\n",
        "    return padded_sequences.astype('float32')"
      ],
      "metadata": {
        "id": "SAIl_gdqfBw3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_train_sequences = get_sequences(tokenizer, X_train)\n",
        "padded_val_sequences = get_sequences(tokenizer, X_val)\n",
        "padded_test_sequences = get_sequences(tokenizer, X_test)"
      ],
      "metadata": {
        "id": "-l4_biICln7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_train_sequences[100808]"
      ],
      "metadata": {
        "id": "VGuisWhGl8pG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8c1a61-984c-4033-804f-0a3ad076a0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.0000e+00, 1.1680e+03, 7.0000e+00, 8.3000e+01, 1.3000e+01,\n",
              "       5.8700e+02, 1.9000e+02, 2.0000e+00, 3.3300e+02, 2.0000e+00,\n",
              "       9.5330e+03, 2.6670e+03, 3.6740e+03, 4.6000e+01, 2.7860e+03,\n",
              "       1.8560e+03, 2.0000e+00, 1.8100e+02, 3.5660e+03, 8.2000e+01,\n",
              "       1.1000e+01, 7.0900e+02, 5.2000e+01, 8.7600e+02, 1.6100e+03,\n",
              "       3.7000e+01, 4.0000e+01, 4.9000e+02, 2.6810e+03, 4.4000e+01,\n",
              "       1.1000e+02, 1.1000e+01, 2.6670e+03, 3.8800e+02, 1.5520e+03,\n",
              "       3.6740e+03, 1.7490e+03, 1.3700e+02, 9.1800e+02, 6.4530e+03,\n",
              "       5.7000e+01, 5.7000e+01, 1.7180e+03, 6.9000e+01, 1.9860e+03,\n",
              "       8.0000e+02, 1.2600e+02, 2.5000e+01, 1.5985e+04, 4.0800e+02,\n",
              "       1.8100e+02, 1.3140e+03, 1.7180e+03, 5.3800e+02, 3.5700e+02,\n",
              "       6.0300e+02, 2.7330e+03, 9.0000e+00, 2.0300e+02, 1.0170e+03,\n",
              "       8.1240e+03, 4.6000e+01, 5.4000e+01, 1.1000e+01, 4.9600e+02,\n",
              "       2.8000e+02, 2.2690e+03, 2.7720e+03, 5.8550e+03, 5.1728e+04,\n",
              "       9.1800e+02, 1.3012e+04, 2.2000e+01, 5.8700e+02, 5.2000e+01,\n",
              "       1.7180e+03, 1.7524e+04, 1.1000e+01, 0.0000e+00, 0.0000e+00,\n",
              "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "       0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Create Embedding from Glove embeddings and Build model"
      ],
      "metadata": {
        "id": "soN8yKR885Om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('/content/drive/MyDrive/NLP/glove_word_vec/glove.6B.100d.txt')\n",
        "\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n",
        "print(f'Loaded {len(embeddings_index)} word vectors')\n",
        "\n",
        "# generate embedding matrix by mapping the vocabulary to the pretrained word embeddings:\n",
        "\n",
        "# create a weight matrix for words in training reviews\n",
        "embedding_mat = np.zeros((vocab_size, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    embedding_vec = embeddings_index.get(word)\n",
        "    if embedding_vec is not None:\n",
        "        embedding_mat[i] = embedding_vec\n"
      ],
      "metadata": {
        "id": "Hnzg-hC5GJYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03479c3c-ce6f-4334-8271-24019ae951b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 400001 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining model architeture\n",
        "model=tf.keras.Sequential()\n",
        "\n",
        "#embedding layer\n",
        "model.add(Embedding(vocab_size,100,weights=[embedding_matrix],input_length=100,trainable=False)) \n",
        "\n",
        "#lstm layer\n",
        "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
        "\n",
        "#Global Maxpooling\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "#Dense Layer\n",
        "model.add(Dense(64,activation='tanh')) \n",
        "model.add(Dense(1,activation='sigmoid')) \n",
        "\n",
        "#loss function, metrics, optimizer\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01), \n",
        "              loss='binary_crossentropy',metrics=[\"acc\"]) \n",
        "\n",
        "#Adding callbacks\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
        "checkpoint=ModelCheckpoint('/content/drive/MyDrive/NLP/best_model.h5',\n",
        "                                      monitor='val_acc',\n",
        "                                      mode='max', save_best_only=True,verbose=1)  \n",
        "\n",
        "#Print summary of model\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJEFR1GZXigI",
        "outputId": "778d2b99-d4aa-47d0-dee1-589dad0e1662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          109848100 \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 128)          117248    \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 128)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109,973,669\n",
            "Trainable params: 125,569\n",
            "Non-trainable params: 109,848,100\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Latest Model"
      ],
      "metadata": {
        "id": "EAjcZVYuhe3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model:\n",
        "\n",
        "history = model.fit(padded_train_sequences,\n",
        "                    np.array(y_train),batch_size=1024,epochs=10,\n",
        "                    validation_data=(padded_val_sequences,np.array(y_val)),\n",
        "                    verbose=1,callbacks=[es,checkpoint])"
      ],
      "metadata": {
        "id": "a5CKcuaXYYip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating our model on the Test Data"
      ],
      "metadata": {
        "id": "bZsZ6KyEdu3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading best model\n",
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/NLP/best_model.h5')\n",
        "\n",
        "#evaluation \n",
        "_,test_acc = model.evaluate(padded_test_sequences,y_test, batch_size=1024)"
      ],
      "metadata": {
        "id": "7m3ctgvfZlJt"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing on custom Review taken from Amazon"
      ],
      "metadata": {
        "id": "lmr22X2I-kAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(text):\n",
        "  df = pd.DataFrame({'text' : [text]})\n",
        "  preprocess(df)\n",
        "  seq = get_sequences(tokenizer, df['text'])\n",
        "  pred = model.predict(seq)\n",
        "  # res = 'Positive' if pred> 0.5 else 'Negative'\n",
        "  print('Text Sentiment: %.3f' % pred[0][0])"
      ],
      "metadata": {
        "id": "ZNTqBz0UBNPC"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_review=\"these gloves are amazing , they are everything i wanted, quality is impeccable, very comfortable, will definetly buy again\"\n",
        "neutral_review = \"these glasses are alright \"\n",
        "negative_review = \"these are very low quality, wouldnt recommend to anyone\"\n",
        "\n",
        "reviews = [pos_review,neutral_review,negative_review]\n",
        "\n",
        "for rev in reviews:\n",
        "  print(rev) \n",
        "  predict(rev)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njp_tayzCuuE",
        "outputId": "f972283b-d5aa-48b5-edb5-ace6ddcf788d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "these gloves are amazing , they are everything i wanted, quality is impeccable, very comfortable, will definetly buy again\n",
            "Text Sentiment: 0.965\n",
            "these glasses are alright \n",
            "Text Sentiment: 0.671\n",
            "these are very low quality, wouldnt recommend to anyone\n",
            "Text Sentiment: 0.008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing our model to other classifiers"
      ],
      "metadata": {
        "id": "KkKi8lASLCJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BASELINE Classifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dummy_clf = DummyClassifier() # clasiifies by guessing the most frequent label\n",
        "dummy_clf.fit(X_test,y_test)\n",
        "dummy_clf.predict(X_test)\n",
        "dummy_clf.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1skasYNlKx8",
        "outputId": "37fc486e-5e7e-4884-d57d-11d8e778c2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5000077761707025"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing our model to NLTK's TextBlob "
      ],
      "metadata": {
        "id": "IV1HbvFLgzGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "def sentiment_calc(text):\n",
        "    try:\n",
        "        return TextBlob(text).sentiment.polarity\n",
        "    except:\n",
        "        return None\n",
        "def get_sentiment_score(df):\n",
        "  df['sentiment'] = df['text'].apply(sentiment_calc)\n",
        "\n",
        "  df.loc[df['sentiment'] >= 0, 'sentiment'] = 1\n",
        "  df.loc[df['sentiment'] < 0, 'sentiment'] = 0\n",
        "  correct = 0\n",
        "  for label,score in zip(df['label'],df['sentiment']):\n",
        "    if label == score:\n",
        "      correct += 1\n",
        "  total = df['sentiment'].count()\n",
        "  acc = correct/total\n",
        "  return acc\n",
        "\n"
      ],
      "metadata": {
        "id": "fBSUFA06LKgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Baseline Classifier accuracy: {dummy_clf.score(X_test,y_test)}\\n')\n",
        "print(f'TextBlob Accuracy on Test Data: {get_sentiment_score(test_data)}\\n')\n",
        "print(f'Our Model Accuracy on Test Data: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDip8UeXKga2",
        "outputId": "ce937b90-ce51-4817-8df2-4676c79a7bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline Classifier accuracy: 0.5000077761707025\n",
            "\n",
            "TextBlob Accuracy on Test Data: 0.6634784366786419\n",
            "\n",
            "Our Model Accuracy on Test Data: 0.898804783821106\n"
          ]
        }
      ]
    }
  ]
}